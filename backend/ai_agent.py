"""
Agente de IA para atendimento autom√°tico ao cidad√£o - Suporte m√∫ltiplos provedores
"""
import os
import logging
from typing import Optional, Dict, Any
from datetime import datetime
from .ai_providers import AIProviderFactory

logger = logging.getLogger(__name__)

class CidadaoAIAgent:
    """Agente de IA especializado em atendimento ao cidad√£o"""
    
    def __init__(self):
        self.provider = None
        self.system_prompt = self._get_system_prompt()
        self.conversation_memory = {}  # Para manter contexto das conversas
        
        # Configurar provedor de IA
        self._setup_ai_provider()
    
    def _setup_ai_provider(self):
        """Configurar provedor de IA baseado nas vari√°veis de ambiente"""
        # Prioridade: Groq > OpenAI > Anthropic
        provider_configs = [
            ("groq", os.getenv("GROQ_API_KEY")),
            ("openai", os.getenv("OPENAI_API_KEY")),
            ("anthropic", os.getenv("ANTHROPIC_API_KEY"))
        ]
        
        for provider_name, api_key in provider_configs:
            if api_key:
                self.provider = AIProviderFactory.create_provider(provider_name, api_key)
                if self.provider and self.provider.is_available():
                    logger.info(f"‚úÖ Provedor {provider_name} configurado e dispon√≠vel")
                    return
        
        logger.warning("‚ö†Ô∏è Nenhum provedor de IA configurado - Agente desabilitado")
        self.provider = None
    
    def _get_system_prompt(self) -> str:
        """Prompt do sistema para o agente"""
        return """
        Voc√™ √© um assistente virtual especializado em atendimento ao cidad√£o para prefeituras brasileiras.
        
        Suas principais responsabilidades:
        - Fornecer informa√ß√µes sobre servi√ßos municipais
        - Orientar sobre documentos e procedimentos
        - Explicar quest√µes tribut√°rias (IPTU, ISS, etc.)
        - Informar sobre sa√∫de, educa√ß√£o e outros servi√ßos p√∫blicos
        - Ser prestativo, educado e profissional
        
        Diretrizes importantes:
        - Use linguagem clara e acess√≠vel
        - Seja sempre cort√™s e respeitoso
        - Se n√£o souber algo espec√≠fico, oriente o cidad√£o a entrar em contato com o √≥rg√£o respons√°vel
        - Mantenha foco em informa√ß√µes gerais e orienta√ß√µes b√°sicas
        - Se a quest√£o for complexa, sugira que o cidad√£o fale com um t√©cnico humano
        
        Formato das respostas:
        - Seja direto e objetivo
        - Use emojis moderadamente para tornar a comunica√ß√£o mais amig√°vel
        - Sempre termine oferecendo ajuda adicional
        
        Exemplo de resposta:
        "Ol√°! Para informa√ß√µes sobre IPTU, voc√™ pode consultar o portal da prefeitura ou ligar para a Secretaria da Fazenda. Posso ajud√°-lo com mais alguma coisa?"
        """
    
    async def process_message(self, message: str, conversation_id: int, contact_info: Dict[str, Any] = None) -> Optional[str]:
        """
        Processar mensagem e gerar resposta autom√°tica
        
        Args:
            message: Mensagem recebida do cidad√£o
            conversation_id: ID da conversa
            contact_info: Informa√ß√µes do contato (opcional)
        
        Returns:
            Resposta gerada pelo agente ou None se erro
        """
        logger.info(f"ü§ñ IN√çCIO PROCESSAMENTO IA - Conversa {conversation_id}")
        logger.info(f"üìù Mensagem recebida: {message[:100]}...")
        logger.info(f"üîß Provedor atual: {self.get_provider_name()}")
        
        if not self.provider:
            logger.error("üö® ERRO: Provedor de IA n√£o dispon√≠vel")
            return None
        
        if not self.provider.is_available():
            logger.error(f"üö® ERRO: Provedor {self.get_provider_name()} n√£o est√° dispon√≠vel")
            return None
        
        try:
            # Preparar contexto da conversa
            conversation_key = f"conv_{conversation_id}"
            
            # Obter hist√≥rico da conversa (se existir)
            conversation_history = self.conversation_memory.get(conversation_key, [])
            
            # Adicionar mensagem atual ao hist√≥rico
            conversation_history.append({
                "role": "user",
                "content": message,
                "timestamp": datetime.now().isoformat()
            })
            
            # Preparar mensagens para o provedor
            messages = [{"role": "system", "content": self.system_prompt}]
            
            # Adicionar hist√≥rico (√∫ltimas 5 mensagens para manter contexto)
            for msg in conversation_history[-5:]:
                messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })
            
            logger.info(f"üöÄ ENVIANDO PARA {self.provider.get_provider_name()}: {message[:100]}...")
            logger.info(f"üìä Mensagens preparadas: {len(messages)}")
            
            # Chamar provedor de IA
            ai_response = await self.provider.generate_response(
                messages=messages,
                max_tokens=300,
                temperature=0.7,
                top_p=0.9
            )
            
            logger.info(f"üì• RESPOSTA RECEBIDA: {ai_response[:200] if ai_response else 'NENHUMA'}...")
            
            if not ai_response:
                logger.error("üö® ERRO: Provedor n√£o retornou resposta")
                return self._get_fallback_response()
            
            # Adicionar resposta ao hist√≥rico
            conversation_history.append({
                "role": "assistant",
                "content": ai_response,
                "timestamp": datetime.now().isoformat()
            })
            
            # Manter apenas √∫ltimas 10 mensagens para n√£o sobrecarregar
            self.conversation_memory[conversation_key] = conversation_history[-10:]
            
            logger.info(f"‚úÖ Resposta gerada: {ai_response[:100]}...")
            
            return ai_response
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao processar mensagem com {self.provider.get_provider_name() if self.provider else 'IA'}: {e}")
            return self._get_fallback_response()
    
    def _get_fallback_response(self) -> str:
        """Resposta de fallback quando IA falha"""
        logger.error("üö® FALLBACK ATIVADO - IA REAL N√ÉO FUNCIONOU!")
        return "üö® ERRO: IA n√£o conseguiu processar. Provedor ativo: " + self.get_provider_name()
    
    def is_available(self) -> bool:
        """Verificar se o agente est√° dispon√≠vel"""
        return self.provider is not None and self.provider.is_available()
    
    def get_provider_name(self) -> str:
        """Obter nome do provedor atual"""
        return self.provider.get_provider_name() if self.provider else "Nenhum"
    
    def get_conversation_context(self, conversation_id: int) -> list:
        """Obter contexto de uma conversa espec√≠fica"""
        conversation_key = f"conv_{conversation_id}"
        return self.conversation_memory.get(conversation_key, [])
    
    def clear_conversation_context(self, conversation_id: int):
        """Limpar contexto de uma conversa espec√≠fica"""
        conversation_key = f"conv_{conversation_id}"
        if conversation_key in self.conversation_memory:
            del self.conversation_memory[conversation_key]
            logger.info(f"Contexto da conversa {conversation_id} limpo")

# Inst√¢ncia global do agente
ai_agent = CidadaoAIAgent()
